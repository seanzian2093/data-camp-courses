# Clean Data with PySpark

## Install JDK

* Download and Install - [Microsoft Built OpenJDK](https://learn.microsoft.com/en-us/java/openjdk/download)
* Setup JAVA_HOME environment variable to the folder that contains `bin` foler and others
* Restart shell

## DataFrame Details

* Defining a schema
* Immutability and lazy processing
* Understanding Parquet

## Manipulating DataFrame in real world

* DataFrame column operations
  * Filtering column content
  * Modifying DataFrame columns
* Conditional DataFrame column operations
  * when
  * when and otherwise
* User defined functions
* Partitioning and lazy processing
  * Adding ID field
  * IDs with different partitions
  * More tricks

## Improving Performance

* Caching
* Improving import performance
* Cluster configuration
* Performance improvement
  * Join with broadcasting

## Complex Processing and Data Pipeline

* Data handling techniques
  * Removing comment lines
* Data validation
* Final analysis and delivery
