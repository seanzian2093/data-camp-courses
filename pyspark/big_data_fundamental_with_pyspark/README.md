# Big Data Fundamental with PySpark

## Introduction

* Understanding SparkContext
  * SparkContext is entry point to RDD
  * SparkSession is entry point to interact with DataFrame
* Interactive Use of PySpark Shell

## Programming in PySpark RDD's

* Abstracting data using RDD
* Partitions in RDD
* Basic RDD transformation and actions
  * Map and collect
  * Filter and count
* Pair RDD in PySpark
  * Reducing by key and collect
  * Sorting by key and collect
* Advanced RDD actions
  * Counting by key

* Exercise - most common worlds of Shakespear
  * Basic RDD and transformation
  * Removing stop words and reducing the dataset

## PySpark SQL and DataFrame

* Abstracting data with DataFrame
  * SparkContext is entry point to RDD
  * SparkSession is entry point to interact with DataFrame
  * RDD to DataFrame
  * Loading CSV file to PySpark
* Operating on DataFrame in PySpark
  * Inspecting data in PySpark DataFrame
  * Subsetting and cleaning PySpark DataFrame
  * Filtering PySpark DataFrame
* Interacting with DataFrame with PySpark SQL
  * Runing SQL queries programmatically
  * SQL query for filtering tables
* Data visualization in PySPark with DataFrame
* Exercise - FIFA2018

## Machine Learning with PySpark

* Overview of PySpark MLlib
  * pyspark.mllib is built-in library for RDD
  * pyspark.ml is built-in library for DataFrame
* Collaborative filtering
* Classification
* Clustering
